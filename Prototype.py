import streamlit as st
import pandas as pd
import numpy as np
import scipy.stats as stats
from docx import Document
from docx.shared import Pt
from docx.enum.table import WD_TABLE_ALIGNMENT
from io import BytesIO
from PIL import Image
import os
import base64

# ğŸŒˆ ShadyTable ä¸»é¡Œé…è‰²èˆ‡ icon å®šç¾©
PRIMARY_COLOR = "#2E6F72"     # æ·±è—ç¶ 
SECONDARY_COLOR = "#5F6C7B"   # æ˜æ™ºç°
ACCENT_COLOR = "#B8F2E6"      # AIèŒç¶ 
HIGHLIGHT_COLOR = "#FFD23F"   # æª¸æª¬é»ƒ
BG_COLOR = "#FAFAFA"          # å¥¶æ²¹ç™½

ICON_UPLOAD = "ğŸ“¤"
ICON_CONFIG = "ğŸ”§"
ICON_STATS = "ğŸ“Š"
ICON_TABLE = "ğŸ“„"
ICON_EXPORT = "ğŸ’¾"
ICON_WORD = "ğŸ“"
ICON_EXCEL = "ğŸ“¥"

# é é¢è¨­å®š
st.set_page_config(page_title="ShadyTable", layout="wide", page_icon="ğŸ§ ")

# Logo èˆ‡æ¨™é¡Œ
def render_svg(svg_path):
    with open(svg_path, "r", encoding="utf-8") as f:
        svg_content = f.read()
    b64 = base64.b64encode(svg_content.encode("utf-8")).decode("utf-8")
    svg_html = f'<img src="data:image/svg+xml;base64,{b64}" style="width:100%;"/>'
    st.markdown(svg_html, unsafe_allow_html=True)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
svg_path = os.path.join(BASE_DIR, "assets", "shady_logo_banner.svg")

if os.path.exists(svg_path):
    render_svg(svg_path)
    st.markdown(
        f"""
        <div style='text-align: center;'>
            <h1 style='color:{PRIMARY_COLOR}; font-size: 36px;'>ShadyTable</h1>
            <h3 style='color:{SECONDARY_COLOR};'>ã€Œå­¸é•·ï¼Œæˆ‘ä¾†ã€</h3>
        </div>
        """,
        unsafe_allow_html=True
    )
else:
    st.warning("âš ï¸ ç„¡æ³•è¼‰å…¥ Logoï¼Œè«‹ç¢ºèªåœ–ç‰‡è·¯å¾‘æ­£ç¢ºã€‚")

st.markdown(
    f"<h1 style='color:{PRIMARY_COLOR}'>ğŸ§  ShadyTable - æ™ºèƒ½ Table 1 ç„¡ç—›ç”Ÿæˆå™¨</h1>",
    unsafe_allow_html=True
)

# Step 1: ä¸Šå‚³è³‡æ–™
st.markdown(f"### {ICON_UPLOAD} <span style='color:{SECONDARY_COLOR}'>Step 1: ä¸Šå‚³è³‡æ–™æª”æ¡ˆ</span>", unsafe_allow_html=True)
st.markdown("âš ï¸ **è«‹å‹™å¿…ç§»é™¤æ‰€æœ‰å€‹è³‡æ¬„ä½ï¼ˆå¦‚å§“åã€ç—…æ­·è™Ÿç­‰ï¼‰ï¼Œé¿å…é•åè³‡æ–™å®‰å…¨è¦ç¯„ï¼**")
uploaded_file = st.file_uploader("è«‹é¸æ“‡ Excel æˆ– CSV æª”", type=["csv", "xlsx"])

if uploaded_file:
    try:
        raw_df = pd.read_csv(uploaded_file) if uploaded_file.name.endswith(".csv") else pd.read_excel(uploaded_file)
        raw_df.replace(["NA", "na", "Na", ""], np.nan, inplace=True)

        df = raw_df.copy()

        personal_info_keywords = ["name", "Name", "å§“å", "chart", "Chart_No", "ç—…æ­·è™Ÿ"]
        alert_cols = [col for col in df.columns if any(key in col for key in personal_info_keywords)]
        if alert_cols:
            st.warning(f"âš ï¸ åµæ¸¬åˆ°å¯èƒ½å«æœ‰å€‹è³‡çš„æ¬„ä½ï¼š{', '.join(alert_cols)}ï¼Œè«‹ç¢ºèªæ˜¯å¦å·²å»è­˜åˆ¥åŒ–ã€‚")

        st.session_state["raw_df"] = raw_df  # å„²å­˜æœªè™•ç†åŸå§‹è³‡æ–™
        st.success("âœ… è³‡æ–™ä¸Šå‚³æˆåŠŸï¼Œç¼ºå€¼å·²è‡ªå‹•è™•ç†ã€‚")
    except Exception as e:
        st.error(f"âŒ æª”æ¡ˆè¼‰å…¥éŒ¯èª¤ï¼š{e}")
        df = None
else:
    df = None


# Step 2: é¸æ“‡è®Šé …
if df is not None:
    st.markdown(f"### {ICON_CONFIG} <span style='color:{SECONDARY_COLOR}'>Step 2: é¸æ“‡è®Šé …</span>", unsafe_allow_html=True)
    all_columns = df.columns.tolist()

    with st.form("var_select_form"):
        group_var = st.selectbox("ğŸ§© åˆ†çµ„è®Šé …ï¼ˆé™å…©çµ„ï¼‰", ["(No Grouping)"] + all_columns)
        cat_vars = st.multiselect("ğŸ”  é¡åˆ¥è®Šé …", all_columns)
        cont_vars = st.multiselect("ğŸ”¢ é€£çºŒè®Šé …", [col for col in all_columns if col not in cat_vars])
        fill_na = st.checkbox("ğŸ©¹ è‡ªå‹•å¡«è£œç¼ºå€¼ï¼ˆå¹³å‡/çœ¾æ•¸ï¼‰", value=True)
        submitted = st.form_submit_button("âœ… ç¢ºèª")

    if submitted:
        if fill_na:
            df = df.copy()
            for col in cont_vars:
                df[col].fillna(df[col].mean(), inplace=True)
            for col in cat_vars:
                df[col].fillna(df[col].mode().iloc[0], inplace=True)
            st.info("å·²å¡«è£œç¼ºå€¼ã€‚")

        st.session_state["df"] = df
        st.session_state["group"] = None if group_var == "(No Grouping)" else group_var
        st.session_state["cat"] = cat_vars
        st.session_state["cont"] = cont_vars
        st.success("âœ… è®Šé …é¸æ“‡å®Œæˆã€‚")

# Step 3: çµ±è¨ˆåˆ†æèˆ‡å‘ˆç¾
        st.markdown(f"### {ICON_STATS} <span style='color:{SECONDARY_COLOR}'>Step 3: çµ±è¨ˆåˆ†æèˆ‡çµæœå‘ˆç¾</span>", unsafe_allow_html=True)

    if "df" in st.session_state:
        df = st.session_state["df"]
        group_var = st.session_state["group"]
        cat_vars = st.session_state["cat"]
        cont_vars = st.session_state["cont"]

                # è¨ˆç®—æ¯å€‹ group çš„æœ‰æ•ˆæ¨£æœ¬æ•¸
        group_labels = []
        if group_var:
            group_counts = df[group_var].value_counts(dropna=False).to_dict()
            group_labels = [f"{g} (n={group_counts[g]})" for g in group_counts.keys()]
        else:
            group_labels = ["Overall"]

        result_rows = []

        def normality_test(data):
            if len(data.dropna()) < 3:
                return False
            p = stats.shapiro(data.dropna())[1]
            return p > 0.05

        def format_continuous(series):
            mean = series.mean()
            std = series.std()
            median = series.median()
            q1 = series.quantile(0.25)
            q3 = series.quantile(0.75)
            return f"{mean:.1f} Â± {std:.1f}", f"{median:.1f} [{q1:.1f}-{q3:.1f}]"

        def format_p(p):
            if p < 0.001:
                return "<0.001***"
            elif p < 0.01:
                return f"{p:.3f}**"
            elif p < 0.05:
                return f"{p:.3f}*"
            else:
                return f"{p:.3f}"

        # é¡åˆ¥è®Šé …
        for var in cat_vars:
            total = len(df)
            raw_df = st.session_state.get("raw_df", df)
            na_pct = raw_df[var].isna().mean() * 100
            row_header = {
                "Variable": f"**{var}**",
                "Missing (%)": f"{na_pct:.1f}%",
                "P": "",
                "Normality": "-",
                "Method": ""
            }
            sub_rows = []

            if group_var:
                ct = pd.crosstab(df[var], df[group_var])
                if ct.shape[1] == 2 and (ct.values < 5).sum() > 0:
                    _, p = stats.fisher_exact(ct.values)
                    row_header["Method"] = "Fisher's exact"
                else:
                    _, p, _, _ = stats.chi2_contingency(ct)
                    row_header["Method"] = "Chi-square"
                row_header["P"] = format_p(p)

                for level in ct.index:
                    sub_row = {"Variable": f"ã€€{level}", "Missing (%)": "", "P": "", "Normality": "", "Method": ""}
                    for g in ct.columns:
                        count = ct.loc[level, g]
                        total = ct[g].sum()
                        label = f"{g} (n={group_counts[g]})"
                        sub_row[label] = f"{count} ({count/total*100:.1f}%)"
                    sub_rows.append(sub_row)
            else:
                counts = df[var].value_counts(dropna=False)
                for level, count in counts.items():
                    sub_rows.append({
                        "Variable": f"ã€€{level}",
                        "Missing (%)": "", "P": "", "Normality": "", "Method": "",
                        "Overall": f"{count} ({count/len(df)*100:.1f}%)"
                    })
                row_header["P"] = "-"
                row_header["Method"] = "-"

            result_rows.append(row_header)
            result_rows.extend(sub_rows)

        # é€£çºŒè®Šé …
        for var in cont_vars:
            total = len(df)
            raw_df = st.session_state.get("raw_df", df)
            na_pct = raw_df[var].isna().mean() * 100
            s = df[var]
            is_normal = normality_test(s)
            method = "t-test" if is_normal else "Mannâ€“Whitney U"

            row_header = {
                "Variable": f"**{var}**",
                "Missing (%)": f"{na_pct:.1f}%",
                "P": "",
                "Normality": "Yes" if is_normal else "No",
                "Method": method
            }
            row = {"Variable": "ã€€Value", "Missing (%)": "", "P": "", "Normality": "", "Method": ""}

            if group_var:
                group_samples = [df[df[group_var] == g][var].dropna() for g in group_counts.keys()]
                for g, s_group in zip(group_counts.keys(), group_samples):
                    mean_std, med_iqr = format_continuous(s_group)
                    label = f"{g} (n={group_counts[g]})"
                    row[label] = mean_std if is_normal else med_iqr

                if len(group_samples) == 2:
                    if is_normal:
                        _, p = stats.ttest_ind(*group_samples, nan_policy="omit")
                    else:
                        _, p = stats.mannwhitneyu(*group_samples)
                    row_header["P"] = format_p(p)
                else:
                    row_header["P"] = "-"
            else:
                mean_std, med_iqr = format_continuous(s.dropna())
                row["Overall"] = mean_std if is_normal else med_iqr
                row_header["P"] = "-"

            result_rows.append(row_header)
            result_rows.append(row)

        table1 = pd.DataFrame(result_rows)

        # é‡æ’æ¬„ä½ï¼šVariable, [Group(s)], Missing (%), P, Normality, Method
        fixed_cols = ["Variable", "Missing (%)", "P", "Normality", "Method"]
        dynamic_cols = [col for col in table1.columns if col not in fixed_cols]
        col_order = ["Variable"] + dynamic_cols + ["Missing (%)", "P", "Normality", "Method"]
        table1 = table1[col_order]

        st.subheader("ğŸ“„ Table 1 çµ±è¨ˆæ‘˜è¦")
        st.dataframe(table1, use_container_width=True)

        # Step 4: åŒ¯å‡º
        st.markdown("---")
        st.markdown(f"### {ICON_EXPORT} <span style='color:{SECONDARY_COLOR}'>Step 4: åŒ¯å‡ºçµæœ</span>", unsafe_allow_html=True)
        col1, col2 = st.columns(2)

        with col1:
            def export_to_excel(df):
                output = BytesIO()
                df.to_excel(output, index=False)
                output.seek(0)
                return output

            excel_data = export_to_excel(table1)
            st.download_button("ğŸ“¥ åŒ¯å‡º Excel", data=excel_data, file_name="Table1_Shady.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        with col2:
            def export_to_word(df):
                doc = Document()
                doc.add_heading("Table 1 Summary", level=1)
                table = doc.add_table(rows=1, cols=len(df.columns))
                table.alignment = WD_TABLE_ALIGNMENT.LEFT
                hdr_cells = table.rows[0].cells
                for i, col in enumerate(df.columns):
                    hdr_cells[i].text = col

                for _, row in df.iterrows():
                    row_cells = table.add_row().cells
                    for i, val in enumerate(row):
                        row_cells[i].text = str(val)

                word_stream = BytesIO()
                doc.save(word_stream)
                word_stream.seek(0)
                return word_stream

            word_data = export_to_word(table1)
            st.download_button("ğŸ“ åŒ¯å‡º Word", data=word_data, file_name="Table1_Shady.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

        # Step 5: ç”¢å‡ºæ–‡å­—æ‘˜è¦
        st.markdown("---")
        st.markdown(f"### ğŸ¤– <span style='color:{SECONDARY_COLOR}'>Step 5: è‡ªå‹•ç”¢å‡º Results æ®µè½</span>", unsafe_allow_html=True)

        if st.button("ğŸ§  ä½¿ç”¨ ChatGPT æ’°å¯«çµæœæ‘˜è¦"):
            with st.spinner("ğŸ¤– æ­£åœ¨è«‹ ChatGPT æ’°å¯«æ‘˜è¦ï¼Œè«‹ç¨å€™..."):
                try:
                    from openai import OpenAI
                    from dotenv import load_dotenv
                    load_dotenv(dotenv_path="./keys.env")
                    import os

                    client = OpenAI(api_key= st.secrets["OPENAI_API_KEY"])

                    prompt = f"""ä½ æ˜¯ä¸€ä½å”åŠ©æ’°å¯«é†«å­¸è«–æ–‡çš„AIåŠ©æ‰‹ã€‚è«‹æ ¹æ“šä¸‹åˆ—Table 1çµ±è¨ˆçµæœï¼Œæ’°å¯«ä¸€æ®µè‹±æ–‡Resultsæ‘˜è¦æ®µè½ï¼Œä¸éœ€è¦æ¨è«–ï¼Œåªéœ€è¦æè¿°å„è®Šé …çš„æ•˜è¿°çµ±è¨ˆèˆ‡på€¼çš„å·®ç•°å³å¯ã€‚\n\n{table1.to_string(index=False)}\n\nè«‹ç”¨æ­£å¼è‹±æ–‡å¯«ä¸€æ®µ200å­—å…§çš„æ®µè½ä½œç‚ºResultsã€‚"""

                    response = client.chat.completions.create(
                        model="gpt-4",
                        messages=[
                            {"role": "system", "content": "You are a medical research assistant specialized in academic writing."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.3,
                        max_tokens=400
                    )

                    result_text = response.choices[0].message.content
                    st.markdown("âœ… **è‡ªå‹•ç”¢å‡º Results æ®µè½å¦‚ä¸‹ï¼š**")
                    st.text_area("Results", value=result_text, height=200)

                    def export_results_to_word(text):
                        doc = Document()
                        doc.add_heading("Results", level=1)
                        para = doc.add_paragraph(text)
                        para.style.font.size = Pt(12)
                        word_stream = BytesIO()
                        doc.save(word_stream)
                        word_stream.seek(0)
                        return word_stream

                    st.markdown("### ğŸ“ ä¸‹è¼‰ Results Word æª”")
                    word_result = export_results_to_word(result_text)
                    st.download_button(
                        label="ğŸ“ ä¸‹è¼‰ Results.docx",
                        data=word_result,
                        file_name="Results_Shady.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
                except Exception as e:
                    st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")


